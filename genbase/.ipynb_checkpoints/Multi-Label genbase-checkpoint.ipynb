{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc : https://cometa.ujaen.es/datasets/genbase\n",
    "# https://sci2s.ugr.es/keel/dataset/data/multilabel/genbase-names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# show graphs in jupyter\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# display all columns/rows and what's inside\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/multi-label-text-classification-5c505fdedca8#--responses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from itertools import cycle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.ext import Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of metrics\n",
    "Evals = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-Label Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662, 1213)\n"
     ]
    }
   ],
   "source": [
    "# Read data from file 'filename.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, rows, column names with read_csv (see later) \n",
    "data = pd.read_csv(\"genbase.csv\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "print(data.shape)\n",
    "# X_train, y_train\n",
    "y = data.iloc[:,-27:]\n",
    "X = data.iloc[:,:-27]\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "X.astype('object')\n",
    "y.astype('object')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>PS00010</th>\n",
       "      <th>PS00011</th>\n",
       "      <th>PS00012</th>\n",
       "      <th>PS00014</th>\n",
       "      <th>PS00017</th>\n",
       "      <th>PS00018</th>\n",
       "      <th>PS00019</th>\n",
       "      <th>PS00020</th>\n",
       "      <th>PS00021</th>\n",
       "      <th>PS00022</th>\n",
       "      <th>PS00023</th>\n",
       "      <th>PS00024</th>\n",
       "      <th>PS00025</th>\n",
       "      <th>PS00026</th>\n",
       "      <th>PS00027</th>\n",
       "      <th>PS00032</th>\n",
       "      <th>PS00033</th>\n",
       "      <th>PS00034</th>\n",
       "      <th>PS00035</th>\n",
       "      <th>PS00045</th>\n",
       "      <th>PS00046</th>\n",
       "      <th>PS00047</th>\n",
       "      <th>PS00048</th>\n",
       "      <th>PS00049</th>\n",
       "      <th>PS00050</th>\n",
       "      <th>PS00058</th>\n",
       "      <th>PS00059</th>\n",
       "      <th>PS00060</th>\n",
       "      <th>PS00061</th>\n",
       "      <th>PS00062</th>\n",
       "      <th>PS00063</th>\n",
       "      <th>PS00064</th>\n",
       "      <th>PS00065</th>\n",
       "      <th>PS00066</th>\n",
       "      <th>PS00067</th>\n",
       "      <th>PS00068</th>\n",
       "      <th>PS00069</th>\n",
       "      <th>PS00070</th>\n",
       "      <th>PS00071</th>\n",
       "      <th>PS00072</th>\n",
       "      <th>PS00073</th>\n",
       "      <th>PS00074</th>\n",
       "      <th>PS00084</th>\n",
       "      <th>PS00085</th>\n",
       "      <th>PS00086</th>\n",
       "      <th>PS00087</th>\n",
       "      <th>PS00088</th>\n",
       "      <th>PS00089</th>\n",
       "      <th>PS00090</th>\n",
       "      <th>PS00091</th>\n",
       "      <th>PS00092</th>\n",
       "      <th>PS00093</th>\n",
       "      <th>PS00094</th>\n",
       "      <th>PS00095</th>\n",
       "      <th>PS00096</th>\n",
       "      <th>PS00097</th>\n",
       "      <th>PS00098</th>\n",
       "      <th>PS00099</th>\n",
       "      <th>PS00100</th>\n",
       "      <th>PS00101</th>\n",
       "      <th>PS00102</th>\n",
       "      <th>PS00103</th>\n",
       "      <th>PS00111</th>\n",
       "      <th>PS00112</th>\n",
       "      <th>PS00113</th>\n",
       "      <th>PS00114</th>\n",
       "      <th>PS00115</th>\n",
       "      <th>PS00116</th>\n",
       "      <th>PS00117</th>\n",
       "      <th>PS00118</th>\n",
       "      <th>PS00119</th>\n",
       "      <th>PS00120</th>\n",
       "      <th>PS00121</th>\n",
       "      <th>PS00122</th>\n",
       "      <th>PS00123</th>\n",
       "      <th>PS00128</th>\n",
       "      <th>PS00129</th>\n",
       "      <th>PS00130</th>\n",
       "      <th>PS00131</th>\n",
       "      <th>PS00132</th>\n",
       "      <th>PS00133</th>\n",
       "      <th>PS00134</th>\n",
       "      <th>PS00135</th>\n",
       "      <th>PS00136</th>\n",
       "      <th>PS00137</th>\n",
       "      <th>PS00138</th>\n",
       "      <th>PS00139</th>\n",
       "      <th>PS00152</th>\n",
       "      <th>PS00154</th>\n",
       "      <th>PS00155</th>\n",
       "      <th>PS00156</th>\n",
       "      <th>PS00157</th>\n",
       "      <th>PS00158</th>\n",
       "      <th>PS00159</th>\n",
       "      <th>PS00160</th>\n",
       "      <th>PS00161</th>\n",
       "      <th>PS00162</th>\n",
       "      <th>PS00163</th>\n",
       "      <th>PS00164</th>\n",
       "      <th>PS00165</th>\n",
       "      <th>PS00166</th>\n",
       "      <th>PS00167</th>\n",
       "      <th>PS00168</th>\n",
       "      <th>PS00169</th>\n",
       "      <th>PS00177</th>\n",
       "      <th>PS00178</th>\n",
       "      <th>PS00179</th>\n",
       "      <th>PS00180</th>\n",
       "      <th>PS00181</th>\n",
       "      <th>PS00182</th>\n",
       "      <th>PS00183</th>\n",
       "      <th>PS00184</th>\n",
       "      <th>PS00185</th>\n",
       "      <th>PS00186</th>\n",
       "      <th>PS00187</th>\n",
       "      <th>PS00188</th>\n",
       "      <th>PS00189</th>\n",
       "      <th>PS00190</th>\n",
       "      <th>PS00191</th>\n",
       "      <th>PS00192</th>\n",
       "      <th>PS00193</th>\n",
       "      <th>PS00194</th>\n",
       "      <th>PS00195</th>\n",
       "      <th>PS00196</th>\n",
       "      <th>PS00197</th>\n",
       "      <th>PS00198</th>\n",
       "      <th>PS00199</th>\n",
       "      <th>PS00200</th>\n",
       "      <th>PS00201</th>\n",
       "      <th>PS00202</th>\n",
       "      <th>PS00203</th>\n",
       "      <th>PS00204</th>\n",
       "      <th>PS00205</th>\n",
       "      <th>PS00206</th>\n",
       "      <th>PS00207</th>\n",
       "      <th>PS00208</th>\n",
       "      <th>PS00209</th>\n",
       "      <th>PS00210</th>\n",
       "      <th>PS00211</th>\n",
       "      <th>PS00212</th>\n",
       "      <th>PS00213</th>\n",
       "      <th>PS00214</th>\n",
       "      <th>PS00215</th>\n",
       "      <th>PS00216</th>\n",
       "      <th>PS00217</th>\n",
       "      <th>PS00227</th>\n",
       "      <th>PS00228</th>\n",
       "      <th>PS00229</th>\n",
       "      <th>PS00230</th>\n",
       "      <th>PS00231</th>\n",
       "      <th>PS00232</th>\n",
       "      <th>PS00233</th>\n",
       "      <th>PS00234</th>\n",
       "      <th>PS00235</th>\n",
       "      <th>PS00236</th>\n",
       "      <th>PS00237</th>\n",
       "      <th>PS00238</th>\n",
       "      <th>PS00239</th>\n",
       "      <th>PS00240</th>\n",
       "      <th>PS00242</th>\n",
       "      <th>PS00243</th>\n",
       "      <th>PS00244</th>\n",
       "      <th>PS00245</th>\n",
       "      <th>PS00265</th>\n",
       "      <th>PS00266</th>\n",
       "      <th>PS00267</th>\n",
       "      <th>PS00268</th>\n",
       "      <th>PS00269</th>\n",
       "      <th>PS00270</th>\n",
       "      <th>PS00271</th>\n",
       "      <th>PS00272</th>\n",
       "      <th>PS00273</th>\n",
       "      <th>PS00274</th>\n",
       "      <th>PS00275</th>\n",
       "      <th>PS00276</th>\n",
       "      <th>PS00277</th>\n",
       "      <th>PS00278</th>\n",
       "      <th>PS00279</th>\n",
       "      <th>PS00280</th>\n",
       "      <th>PS00281</th>\n",
       "      <th>PS00282</th>\n",
       "      <th>PS00283</th>\n",
       "      <th>PS00284</th>\n",
       "      <th>PS00285</th>\n",
       "      <th>PS00286</th>\n",
       "      <th>PS00287</th>\n",
       "      <th>PS00288</th>\n",
       "      <th>PS00294</th>\n",
       "      <th>PS00296</th>\n",
       "      <th>PS00297</th>\n",
       "      <th>PS00298</th>\n",
       "      <th>PS00302</th>\n",
       "      <th>PS00303</th>\n",
       "      <th>PS00304</th>\n",
       "      <th>PS00306</th>\n",
       "      <th>PS00307</th>\n",
       "      <th>PS00308</th>\n",
       "      <th>PS00309</th>\n",
       "      <th>PS00310</th>\n",
       "      <th>PS00311</th>\n",
       "      <th>PS00312</th>\n",
       "      <th>PS00313</th>\n",
       "      <th>PS00317</th>\n",
       "      <th>PS00318</th>\n",
       "      <th>PS00319</th>\n",
       "      <th>PS00320</th>\n",
       "      <th>PS00321</th>\n",
       "      <th>PS00322</th>\n",
       "      <th>PS00324</th>\n",
       "      <th>PS00326</th>\n",
       "      <th>PS00327</th>\n",
       "      <th>PS00329</th>\n",
       "      <th>PS00330</th>\n",
       "      <th>PS00331</th>\n",
       "      <th>PS00332</th>\n",
       "      <th>PS00333</th>\n",
       "      <th>PS00335</th>\n",
       "      <th>PS00338</th>\n",
       "      <th>PS00339</th>\n",
       "      <th>PS00341</th>\n",
       "      <th>PS00343</th>\n",
       "      <th>PS00353</th>\n",
       "      <th>PS00354</th>\n",
       "      <th>PS00355</th>\n",
       "      <th>PS00357</th>\n",
       "      <th>PS00358</th>\n",
       "      <th>PS00359</th>\n",
       "      <th>PS00363</th>\n",
       "      <th>PS00364</th>\n",
       "      <th>PS00367</th>\n",
       "      <th>PS00368</th>\n",
       "      <th>PS00369</th>\n",
       "      <th>PS00370</th>\n",
       "      <th>PS00371</th>\n",
       "      <th>PS00372</th>\n",
       "      <th>PS00373</th>\n",
       "      <th>PS00374</th>\n",
       "      <th>PS00375</th>\n",
       "      <th>PS00379</th>\n",
       "      <th>PS00380</th>\n",
       "      <th>PS00381</th>\n",
       "      <th>PS00382</th>\n",
       "      <th>PS00385</th>\n",
       "      <th>PS00389</th>\n",
       "      <th>PS00390</th>\n",
       "      <th>PS00391</th>\n",
       "      <th>PS00392</th>\n",
       "      <th>PS00393</th>\n",
       "      <th>PS00394</th>\n",
       "      <th>...</th>\n",
       "      <th>PS50135</th>\n",
       "      <th>PS50136</th>\n",
       "      <th>PS50137</th>\n",
       "      <th>PS50138</th>\n",
       "      <th>PS50139</th>\n",
       "      <th>PS50140</th>\n",
       "      <th>PS50141</th>\n",
       "      <th>PS50142</th>\n",
       "      <th>PS50143</th>\n",
       "      <th>PS50144</th>\n",
       "      <th>PS50145</th>\n",
       "      <th>PS50146</th>\n",
       "      <th>PS50147</th>\n",
       "      <th>PS50148</th>\n",
       "      <th>PS50149</th>\n",
       "      <th>PS50150</th>\n",
       "      <th>PS50151</th>\n",
       "      <th>PS50152</th>\n",
       "      <th>PS50153</th>\n",
       "      <th>PS50154</th>\n",
       "      <th>PS50155</th>\n",
       "      <th>PS50156</th>\n",
       "      <th>PS50157</th>\n",
       "      <th>PS50158</th>\n",
       "      <th>PS50159</th>\n",
       "      <th>PS50160</th>\n",
       "      <th>PS50161</th>\n",
       "      <th>PS50162</th>\n",
       "      <th>PS50163</th>\n",
       "      <th>PS50164</th>\n",
       "      <th>PS50165</th>\n",
       "      <th>PS50166</th>\n",
       "      <th>PS50167</th>\n",
       "      <th>PS50168</th>\n",
       "      <th>PS50169</th>\n",
       "      <th>PS50170</th>\n",
       "      <th>PS50171</th>\n",
       "      <th>PS50172</th>\n",
       "      <th>PS50173</th>\n",
       "      <th>PS50174</th>\n",
       "      <th>PS50175</th>\n",
       "      <th>PS50176</th>\n",
       "      <th>PS50177</th>\n",
       "      <th>PS50178</th>\n",
       "      <th>PS50179</th>\n",
       "      <th>PS50180</th>\n",
       "      <th>PS50181</th>\n",
       "      <th>PS50182</th>\n",
       "      <th>PS50183</th>\n",
       "      <th>PS50184</th>\n",
       "      <th>PS50185</th>\n",
       "      <th>PS50186</th>\n",
       "      <th>PS50187</th>\n",
       "      <th>PS50188</th>\n",
       "      <th>PS50189</th>\n",
       "      <th>PS50190</th>\n",
       "      <th>PS50191</th>\n",
       "      <th>PS50192</th>\n",
       "      <th>PS50193</th>\n",
       "      <th>PS50194</th>\n",
       "      <th>PS50195</th>\n",
       "      <th>PS50196</th>\n",
       "      <th>PS50197</th>\n",
       "      <th>PS50198</th>\n",
       "      <th>PS50199</th>\n",
       "      <th>PS50200</th>\n",
       "      <th>PS50202</th>\n",
       "      <th>PS50203</th>\n",
       "      <th>PS50204</th>\n",
       "      <th>PS50205</th>\n",
       "      <th>PS50206</th>\n",
       "      <th>PS50207</th>\n",
       "      <th>PS50208</th>\n",
       "      <th>PS50209</th>\n",
       "      <th>PS50210</th>\n",
       "      <th>PS50211</th>\n",
       "      <th>PS50212</th>\n",
       "      <th>PS50213</th>\n",
       "      <th>PS50214</th>\n",
       "      <th>PS50215</th>\n",
       "      <th>PS50216</th>\n",
       "      <th>PS50217</th>\n",
       "      <th>PS50218</th>\n",
       "      <th>PS50219</th>\n",
       "      <th>PS50220</th>\n",
       "      <th>PS50221</th>\n",
       "      <th>PS50222</th>\n",
       "      <th>PS50223</th>\n",
       "      <th>PS50224</th>\n",
       "      <th>PS50225</th>\n",
       "      <th>PS50226</th>\n",
       "      <th>PS50227</th>\n",
       "      <th>PS50228</th>\n",
       "      <th>PS50229</th>\n",
       "      <th>PS50230</th>\n",
       "      <th>PS50231</th>\n",
       "      <th>PS50232</th>\n",
       "      <th>PS50233</th>\n",
       "      <th>PS50234</th>\n",
       "      <th>PS50235</th>\n",
       "      <th>PS50236</th>\n",
       "      <th>PS50237</th>\n",
       "      <th>PS50238</th>\n",
       "      <th>PS50239</th>\n",
       "      <th>PS50240</th>\n",
       "      <th>PS50241</th>\n",
       "      <th>PS50242</th>\n",
       "      <th>PS50243</th>\n",
       "      <th>PS50244</th>\n",
       "      <th>PS50245</th>\n",
       "      <th>PS50246</th>\n",
       "      <th>PS50247</th>\n",
       "      <th>PS50248</th>\n",
       "      <th>PS50249</th>\n",
       "      <th>PS50250</th>\n",
       "      <th>PS50251</th>\n",
       "      <th>PS50252</th>\n",
       "      <th>PS50253</th>\n",
       "      <th>PS50254</th>\n",
       "      <th>PS50255</th>\n",
       "      <th>PS50256</th>\n",
       "      <th>PS50257</th>\n",
       "      <th>PS50258</th>\n",
       "      <th>PS50259</th>\n",
       "      <th>PS50260</th>\n",
       "      <th>PS50261</th>\n",
       "      <th>PS50262</th>\n",
       "      <th>PS50263</th>\n",
       "      <th>PS50264</th>\n",
       "      <th>PS50265</th>\n",
       "      <th>PS50266</th>\n",
       "      <th>PS50267</th>\n",
       "      <th>PS50268</th>\n",
       "      <th>PS50269</th>\n",
       "      <th>PS50270</th>\n",
       "      <th>PS50271</th>\n",
       "      <th>PS50272</th>\n",
       "      <th>PS50273</th>\n",
       "      <th>PS50275</th>\n",
       "      <th>PS50276</th>\n",
       "      <th>PS50277</th>\n",
       "      <th>PS50278</th>\n",
       "      <th>PS50279</th>\n",
       "      <th>PS50280</th>\n",
       "      <th>PS50281</th>\n",
       "      <th>PS50282</th>\n",
       "      <th>PS50283</th>\n",
       "      <th>PS50284</th>\n",
       "      <th>PS50285</th>\n",
       "      <th>PS50286</th>\n",
       "      <th>PS50287</th>\n",
       "      <th>PS50288</th>\n",
       "      <th>PS50290</th>\n",
       "      <th>PS50291</th>\n",
       "      <th>PS50292</th>\n",
       "      <th>PS50293</th>\n",
       "      <th>PS50294</th>\n",
       "      <th>PS50295</th>\n",
       "      <th>PS50296</th>\n",
       "      <th>PS50297</th>\n",
       "      <th>PS50298</th>\n",
       "      <th>PS50299</th>\n",
       "      <th>PS50300</th>\n",
       "      <th>PS50301</th>\n",
       "      <th>PS50302</th>\n",
       "      <th>PS50303</th>\n",
       "      <th>PS50304</th>\n",
       "      <th>PS50305</th>\n",
       "      <th>PS50309</th>\n",
       "      <th>PS50310</th>\n",
       "      <th>PS50311</th>\n",
       "      <th>PS50312</th>\n",
       "      <th>PS50313</th>\n",
       "      <th>PS50314</th>\n",
       "      <th>PS50315</th>\n",
       "      <th>PS50316</th>\n",
       "      <th>PS50317</th>\n",
       "      <th>PS50318</th>\n",
       "      <th>PS50319</th>\n",
       "      <th>PS50320</th>\n",
       "      <th>PS50321</th>\n",
       "      <th>PS50322</th>\n",
       "      <th>PS50323</th>\n",
       "      <th>PS50324</th>\n",
       "      <th>PS50325</th>\n",
       "      <th>PS50326</th>\n",
       "      <th>PS50327</th>\n",
       "      <th>PS50328</th>\n",
       "      <th>PS50330</th>\n",
       "      <th>PS50404</th>\n",
       "      <th>PS50405</th>\n",
       "      <th>PS50600</th>\n",
       "      <th>PS50800</th>\n",
       "      <th>PS50801</th>\n",
       "      <th>PS50802</th>\n",
       "      <th>PS50803</th>\n",
       "      <th>PS50804</th>\n",
       "      <th>PS50805</th>\n",
       "      <th>PS50806</th>\n",
       "      <th>PS50807</th>\n",
       "      <th>PS50808</th>\n",
       "      <th>PS50809</th>\n",
       "      <th>PS50810</th>\n",
       "      <th>PS50811</th>\n",
       "      <th>PS50812</th>\n",
       "      <th>PS50813</th>\n",
       "      <th>PS50814</th>\n",
       "      <th>PS50815</th>\n",
       "      <th>PS50816</th>\n",
       "      <th>PS50817</th>\n",
       "      <th>PS50818</th>\n",
       "      <th>PS50819</th>\n",
       "      <th>PS50820</th>\n",
       "      <th>PS50821</th>\n",
       "      <th>PS50822</th>\n",
       "      <th>PS50823</th>\n",
       "      <th>PS50824</th>\n",
       "      <th>PS50825</th>\n",
       "      <th>PS50826</th>\n",
       "      <th>PS50827</th>\n",
       "      <th>PS50829</th>\n",
       "      <th>PS50830</th>\n",
       "      <th>PS60000</th>\n",
       "      <th>PDOC00154</th>\n",
       "      <th>PDOC00343</th>\n",
       "      <th>PDOC00271</th>\n",
       "      <th>PDOC00064</th>\n",
       "      <th>PDOC00791</th>\n",
       "      <th>PDOC00380</th>\n",
       "      <th>PDOC50007</th>\n",
       "      <th>PDOC00224</th>\n",
       "      <th>PDOC00100</th>\n",
       "      <th>PDOC00670</th>\n",
       "      <th>PDOC50002</th>\n",
       "      <th>PDOC50106</th>\n",
       "      <th>PDOC00561</th>\n",
       "      <th>PDOC50017</th>\n",
       "      <th>PDOC50003</th>\n",
       "      <th>PDOC50006</th>\n",
       "      <th>PDOC50156</th>\n",
       "      <th>PDOC00662</th>\n",
       "      <th>PDOC00018</th>\n",
       "      <th>PDOC50001</th>\n",
       "      <th>PDOC00014</th>\n",
       "      <th>PDOC00750</th>\n",
       "      <th>PDOC50196</th>\n",
       "      <th>PDOC50199</th>\n",
       "      <th>PDOC00660</th>\n",
       "      <th>PDOC00653</th>\n",
       "      <th>PDOC00030</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O00060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O00139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O02741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O08424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O12984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein  PS00010  PS00011  PS00012  PS00014  PS00017  PS00018  PS00019  PS00020  PS00021  PS00022  PS00023  PS00024  PS00025  PS00026  PS00027  \\\n",
       "0  O00060        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1  O00139        0        0        0        0        1        0        0        0        0        0        0        0        0        0        0   \n",
       "2  O02741        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3  O08424        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4  O12984        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00032  PS00033  PS00034  PS00035  PS00045  PS00046  PS00047  PS00048  PS00049  PS00050  PS00058  PS00059  PS00060  PS00061  PS00062  PS00063  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00064  PS00065  PS00066  PS00067  PS00068  PS00069  PS00070  PS00071  PS00072  PS00073  PS00074  PS00084  PS00085  PS00086  PS00087  PS00088  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        1        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00089  PS00090  PS00091  PS00092  PS00093  PS00094  PS00095  PS00096  PS00097  PS00098  PS00099  PS00100  PS00101  PS00102  PS00103  PS00111  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00112  PS00113  PS00114  PS00115  PS00116  PS00117  PS00118  PS00119  PS00120  PS00121  PS00122  PS00123  PS00128  PS00129  PS00130  PS00131  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00132  PS00133  PS00134  PS00135  PS00136  PS00137  PS00138  PS00139  PS00152  PS00154  PS00155  PS00156  PS00157  PS00158  PS00159  PS00160  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00161  PS00162  PS00163  PS00164  PS00165  PS00166  PS00167  PS00168  PS00169  PS00177  PS00178  PS00179  PS00180  PS00181  PS00182  PS00183  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00184  PS00185  PS00186  PS00187  PS00188  PS00189  PS00190  PS00191  PS00192  PS00193  PS00194  PS00195  PS00196  PS00197  PS00198  PS00199  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00200  PS00201  PS00202  PS00203  PS00204  PS00205  PS00206  PS00207  PS00208  PS00209  PS00210  PS00211  PS00212  PS00213  PS00214  PS00215  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00216  PS00217  PS00227  PS00228  PS00229  PS00230  PS00231  PS00232  PS00233  PS00234  PS00235  PS00236  PS00237  PS00238  PS00239  PS00240  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00242  PS00243  PS00244  PS00245  PS00265  PS00266  PS00267  PS00268  PS00269  PS00270  PS00271  PS00272  PS00273  PS00274  PS00275  PS00276  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00277  PS00278  PS00279  PS00280  PS00281  PS00282  PS00283  PS00284  PS00285  PS00286  PS00287  PS00288  PS00294  PS00296  PS00297  PS00298  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00302  PS00303  PS00304  PS00306  PS00307  PS00308  PS00309  PS00310  PS00311  PS00312  PS00313  PS00317  PS00318  PS00319  PS00320  PS00321  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        1        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00322  PS00324  PS00326  PS00327  PS00329  PS00330  PS00331  PS00332  PS00333  PS00335  PS00338  PS00339  PS00341  PS00343  PS00353  PS00354  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00355  PS00357  PS00358  PS00359  PS00363  PS00364  PS00367  PS00368  PS00369  PS00370  PS00371  PS00372  PS00373  PS00374  PS00375  PS00379  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS00380  PS00381  PS00382  PS00385  PS00389  PS00390  PS00391  PS00392  PS00393  PS00394  ...  PS50135  PS50136  PS50137  PS50138  PS50139  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0  ...        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0  ...        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0  ...        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0  ...        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0  ...        0        0        0        0        0   \n",
       "\n",
       "   PS50140  PS50141  PS50142  PS50143  PS50144  PS50145  PS50146  PS50147  PS50148  PS50149  PS50150  PS50151  PS50152  PS50153  PS50154  PS50155  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50156  PS50157  PS50158  PS50159  PS50160  PS50161  PS50162  PS50163  PS50164  PS50165  PS50166  PS50167  PS50168  PS50169  PS50170  PS50171  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50172  PS50173  PS50174  PS50175  PS50176  PS50177  PS50178  PS50179  PS50180  PS50181  PS50182  PS50183  PS50184  PS50185  PS50186  PS50187  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50188  PS50189  PS50190  PS50191  PS50192  PS50193  PS50194  PS50195  PS50196  PS50197  PS50198  PS50199  PS50200  PS50202  PS50203  PS50204  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50205  PS50206  PS50207  PS50208  PS50209  PS50210  PS50211  PS50212  PS50213  PS50214  PS50215  PS50216  PS50217  PS50218  PS50219  PS50220  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50221  PS50222  PS50223  PS50224  PS50225  PS50226  PS50227  PS50228  PS50229  PS50230  PS50231  PS50232  PS50233  PS50234  PS50235  PS50236  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50237  PS50238  PS50239  PS50240  PS50241  PS50242  PS50243  PS50244  PS50245  PS50246  PS50247  PS50248  PS50249  PS50250  PS50251  PS50252  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50253  PS50254  PS50255  PS50256  PS50257  PS50258  PS50259  PS50260  PS50261  PS50262  PS50263  PS50264  PS50265  PS50266  PS50267  PS50268  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50269  PS50270  PS50271  PS50272  PS50273  PS50275  PS50276  PS50277  PS50278  PS50279  PS50280  PS50281  PS50282  PS50283  PS50284  PS50285  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50286  PS50287  PS50288  PS50290  PS50291  PS50292  PS50293  PS50294  PS50295  PS50296  PS50297  PS50298  PS50299  PS50300  PS50301  PS50302  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50303  PS50304  PS50305  PS50309  PS50310  PS50311  PS50312  PS50313  PS50314  PS50315  PS50316  PS50317  PS50318  PS50319  PS50320  PS50321  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50322  PS50323  PS50324  PS50325  PS50326  PS50327  PS50328  PS50330  PS50404  PS50405  PS50600  PS50800  PS50801  PS50802  PS50803  PS50804  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50805  PS50806  PS50807  PS50808  PS50809  PS50810  PS50811  PS50812  PS50813  PS50814  PS50815  PS50816  PS50817  PS50818  PS50819  PS50820  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   PS50821  PS50822  PS50823  PS50824  PS50825  PS50826  PS50827  PS50829  PS50830  PS60000  PDOC00154  PDOC00343  PDOC00271  PDOC00064  PDOC00791  \\\n",
       "0        0        0        0        0        0        0        0        0        0        0          1          0          0          0          0   \n",
       "1        0        0        0        0        0        0        0        0        0        0          0          1          0          0          0   \n",
       "2        0        0        0        0        0        0        0        0        0        0          0          0          1          0          0   \n",
       "3        0        0        0        0        0        0        0        0        0        0          0          0          0          1          0   \n",
       "4        0        0        0        0        0        0        0        0        0        0          0          0          0          0          1   \n",
       "\n",
       "   PDOC00380  PDOC50007  PDOC00224  PDOC00100  PDOC00670  PDOC50002  PDOC50106  PDOC00561  PDOC50017  PDOC50003  PDOC50006  PDOC50156  PDOC00662  \\\n",
       "0          0          0          0          0          0          0          0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0          0          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0          0          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0          0          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0          0          0          0          0          0          0          0   \n",
       "\n",
       "   PDOC00018  PDOC50001  PDOC00014  PDOC00750  PDOC50196  PDOC50199  PDOC00660  PDOC00653  PDOC00030  \n",
       "0          0          0          0          0          0          0          0          0          0  \n",
       "1          0          0          0          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 1213 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Multiple Binary Classifications - (Binary Relevance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1  BinaryRelevance MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4f812323d460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mKERAS_PARAMS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryRelevance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKeras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_model_single_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKERAS_PARAMS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_dense\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\br.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m    147\u001b[0m         X = self._ensure_input_format(\n\u001b[1;32m--> 148\u001b[1;33m             X, sparse_format='csr', enforce_sparse=True)\n\u001b[0m\u001b[0;32m    149\u001b[0m         y = self._ensure_output_format(\n\u001b[0;32m    150\u001b[0m             y, sparse_format='csc', enforce_sparse=True)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\base\\base.py\u001b[0m in \u001b[0;36m_ensure_input_format\u001b[1;34m(self, X, sparse_format, enforce_sparse)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmatrix_creation_function_for_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_output_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                  \"\".format(self.format))\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Read matrix dimensions given, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m###################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             coo_tocsr(M, N, self.nnz, row, col, self.data,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "def create_model_single_class(input_dim, output_dim):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "KERAS_PARAMS = dict(epochs=10, batch_size=100, verbose=0)\n",
    "clf = BinaryRelevance(classifier=Keras(create_model_single_class, False, KERAS_PARAMS), require_dense=[True,True])\n",
    "clf.fit(X_train, y_train)\n",
    "result = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,result.toarray())\n",
    "Micro_Precision = precision_score(y_test,result, average='micro')\n",
    "Micro_Recall = recall_score(y_test,result, average='micro')\n",
    "Micro_F1 = f1_score(y_test,result, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, result.toarray(), average='micro')\n",
    "Macro_Precision = precision_score(y_test,result, average='macro')\n",
    "Macro_Recall = recall_score(y_test,result, average='macro')\n",
    "Macro_F1 = f1_score(y_test,result, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, result.toarray(), average='macro')\n",
    "Samples_Average_Prec = average_precision_score(y_test, result.toarray(), average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, result.toarray(), average='weighted')\n",
    "Hamming_loss = hamming_loss(y_test,result)\n",
    "Ranking_loss = label_ranking_loss(y_test, result.toarray())\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _  = roc_curve(y_test.toarray(), result)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.ravel(), result.toarray().ravel())\n",
    "Micro_Roc_auc = auc(fpr, tpr)\n",
    "Coverage_error = coverage_error(y_test, result.toarray())\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, result.toarray())\n",
    "Jaccard_score = jaccard_score(y_test, result.toarray(), average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, result.toarray(), average='macro')\n",
    "print(\"BinaryReMLP Accuracy = \",Accuracy)\n",
    "print(\"BinaryReMLP Micro_Precision = \",Micro_Precision)\n",
    "print(\"BinaryReMLP Micro_Recall = \",Micro_Recall)\n",
    "print(\"BinaryReMLP Micro_F1 = \",Micro_F1)\n",
    "print(\"BinaryReMLP Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"BinaryReMLP Macro_Precision = \",Macro_Precision)\n",
    "print(\"BinaryReMLP Macro_Recall = \",Macro_Recall)\n",
    "print(\"BinaryReMLP Macro_F1 = \",Macro_F1)\n",
    "print(\"BinaryReMLP Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"BinaryReMLP Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"BinaryReMLP Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"BinaryReMLP Hamming_loss = \",Hamming_loss)\n",
    "print(\"BinaryReMLP Ranking_loss = \",Ranking_loss)\n",
    "print(\"BinaryReMLP Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"BinaryReMLP Coverage_error = \",Coverage_error)\n",
    "print(\"BinaryReMLP label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"BinaryReMLP Jaccard_score = \",Jaccard_score)\n",
    "print(\"BinaryReMLP Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval1 = ['BinaryReMLP',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2  BinaryRelevance SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b07a485c77fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryRelevance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_dense\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\br.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m    147\u001b[0m         X = self._ensure_input_format(\n\u001b[1;32m--> 148\u001b[1;33m             X, sparse_format='csr', enforce_sparse=True)\n\u001b[0m\u001b[0;32m    149\u001b[0m         y = self._ensure_output_format(\n\u001b[0;32m    150\u001b[0m             y, sparse_format='csc', enforce_sparse=True)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\base\\base.py\u001b[0m in \u001b[0;36m_ensure_input_format\u001b[1;34m(self, X, sparse_format, enforce_sparse)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmatrix_creation_function_for_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_output_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                  \"\".format(self.format))\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Read matrix dimensions given, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m###################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             coo_tocsr(M, N, self.nnz, row, col, self.data,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "# initialize Binary Relevance multi-label classifier\n",
    "# with an SVM classifier  # SVM in scikit only supports the X matrix in sparse representation\n",
    "# Setup the classifier\n",
    "classifier = BinaryRelevance(classifier=SVC(), require_dense=[False,True])\n",
    "# Train\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "# In multilabel classification, this function computes subset_accuracy:\n",
    "Accuracy = accuracy_score(y_test,y_pred)  \n",
    "Micro_Precision = precision_score(y_test,y_pred, average='micro')\n",
    "Micro_Recall = recall_score(y_test,y_pred, average='micro')\n",
    "Micro_F1 = f1_score(y_test,y_pred, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, y_pred.toarray(), average='micro')\n",
    "Macro_Precision = precision_score(y_test,y_pred, average='macro')\n",
    "Macro_Recall = recall_score(y_test,y_pred, average='macro')\n",
    "Macro_F1 = f1_score(y_test,y_pred, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, y_pred.toarray(), average='macro')\n",
    "Samples_Average_Prec = average_precision_score(y_test, y_pred.toarray(), average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, y_pred.toarray(), average='weighted')\n",
    "Hamming_loss = hamming_loss(y_test,y_pred)\n",
    "Ranking_loss = label_ranking_loss(y_test, y_pred.toarray())\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _  = roc_curve(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.ravel(), y_pred.toarray().ravel())\n",
    "Micro_Roc_auc = auc(fpr, tpr)\n",
    "Coverage_error = coverage_error(y_test, y_pred.toarray())\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, y_pred.toarray())\n",
    "Jaccard_score = jaccard_score(y_test, y_pred, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, y_pred, average='macro')\n",
    "print(\"BinaryReSVC Accuracy = \",Accuracy)\n",
    "print(\"BinaryReSVC Micro_Precision = \",Micro_Precision)\n",
    "print(\"BinaryReSVC Micro_Recall = \",Micro_Recall)\n",
    "print(\"BinaryReSVC Micro_F1 = \",Micro_F1)\n",
    "print(\"BinaryReSVC Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"BinaryReSVC Macro_Precision = \",Macro_Precision)\n",
    "print(\"BinaryReSVC Macro_Recall = \",Macro_Recall)\n",
    "print(\"BinaryReSVC Macro_F1 = \",Macro_F1)\n",
    "print(\"BinaryReSVC Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"BinaryReSVC Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"BinaryReSVC Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"BinaryReSVC Hamming_loss = \",Hamming_loss)\n",
    "print(\"BinaryReSVC Ranking_loss = \",Ranking_loss)\n",
    "print(\"BinaryReSVC Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"BinaryReSVC Coverage_error = \",Coverage_error)\n",
    "print(\"BinaryReSVC label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"BinaryReSVC Jaccard_score = \",Jaccard_score)\n",
    "print(\"BinaryReSVC Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval2 = ['BinaryReSVC',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3  BinaryRelevance GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-90e95b466953>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Binary Relevance GaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mBinaryReGaussianNB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryRelevance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mBinaryReGaussianNB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mbr_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryReGaussianNB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\br.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m    147\u001b[0m         X = self._ensure_input_format(\n\u001b[1;32m--> 148\u001b[1;33m             X, sparse_format='csr', enforce_sparse=True)\n\u001b[0m\u001b[0;32m    149\u001b[0m         y = self._ensure_output_format(\n\u001b[0;32m    150\u001b[0m             y, sparse_format='csc', enforce_sparse=True)\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\base\\base.py\u001b[0m in \u001b[0;36m_ensure_input_format\u001b[1;34m(self, X, sparse_format, enforce_sparse)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmatrix_creation_function_for_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_output_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                  \"\".format(self.format))\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Read matrix dimensions given, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m###################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             coo_tocsr(M, N, self.nnz, row, col, self.data,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "#Binary Relevance GaussianNB\n",
    "BinaryReGaussianNB = BinaryRelevance(GaussianNB())\n",
    "BinaryReGaussianNB.fit(X_train,y_train)\n",
    "br_predictions = BinaryReGaussianNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,br_predictions.toarray())\n",
    "Micro_Precision = precision_score(y_test,br_predictions, average='micro')\n",
    "Micro_Recall = recall_score(y_test,br_predictions, average='micro')\n",
    "Micro_F1 = f1_score(y_test,br_predictions, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, br_predictions.toarray(), average='micro')\n",
    "Macro_Precision = precision_score(y_test,br_predictions, average='macro')\n",
    "Macro_Recall = recall_score(y_test,br_predictions, average='macro')\n",
    "Macro_F1 = f1_score(y_test,br_predictions, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, br_predictions.toarray(), average='macro')\n",
    "Samples_Average_Prec = average_precision_score(y_test, br_predictions.toarray(), average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, br_predictions.toarray(), average='weighted')\n",
    "Hamming_loss = hamming_loss(y_test,br_predictions)\n",
    "Ranking_loss = label_ranking_loss(y_test, br_predictions.toarray())\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _  = roc_curve(y_test.toarray(), br_predictions)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.ravel(), br_predictions.toarray().ravel())\n",
    "Micro_Roc_auc = auc(fpr, tpr)\n",
    "Coverage_error = coverage_error(y_test, br_predictions.toarray())\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, br_predictions.toarray())\n",
    "Jaccard_score = jaccard_score(y_test, br_predictions, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, br_predictions, average='macro')\n",
    "print(\"BinaryReGaussianNB Accuracy = \",Accuracy)\n",
    "print(\"BinaryReGaussianNB Micro_Precision = \",Micro_Precision)\n",
    "print(\"BinaryReGaussianNB Micro_Recall = \",Micro_Recall)\n",
    "print(\"BinaryReGaussianNB Micro_F1 = \",Micro_F1)\n",
    "print(\"BinaryReGaussianNB Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"BinaryReGaussianNB Macro_Precision = \",Macro_Precision)\n",
    "print(\"BinaryReGaussianNB Macro_Recall = \",Macro_Recall)\n",
    "print(\"BinaryReGaussianNB Macro_F1 = \",Macro_F1)\n",
    "print(\"BinaryReGaussianNB Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"BinaryReGaussianNB Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"BinaryReGaussianNB Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"BinaryReGaussianNB Hamming_loss = \",Hamming_loss)\n",
    "print(\"BinaryReGaussianNB Ranking_loss = \",Ranking_loss)\n",
    "print(\"BinaryReGaussianNB Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"BinaryReGaussianNB Coverage_error = \",Coverage_error)\n",
    "print(\"BinaryReGaussianNB label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"BinaryReGaussianNB Jaccard_score = \",Jaccard_score)\n",
    "print(\"BinaryReGaussianNB Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval3 = ['BinaryReGaussianNB',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Label Powerset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-94fe8990f454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## initialize label powerset multi-label classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlp_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelPowerset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlp_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlp_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlp_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\lp.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m    137\u001b[0m         X = self._ensure_input_format(\n\u001b[1;32m--> 138\u001b[1;33m             X, sparse_format='csr', enforce_sparse=True)\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         self.classifier.fit(self._ensure_input_format(X),\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\base\\base.py\u001b[0m in \u001b[0;36m_ensure_input_format\u001b[1;34m(self, X, sparse_format, enforce_sparse)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmatrix_creation_function_for_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_output_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                  \"\".format(self.format))\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Read matrix dimensions given, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m###################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             coo_tocsr(M, N, self.nnz, row, col, self.data,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "## initialize label powerset multi-label classifier\n",
    "lp_classifier = LabelPowerset(LogisticRegression())\n",
    "lp_classifier.fit(X_train, y_train)\n",
    "lp_predictions = lp_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,lp_predictions.toarray())\n",
    "Micro_Precision = precision_score(y_test,lp_predictions, average='micro')\n",
    "Micro_Recall = recall_score(y_test,lp_predictions, average='micro')\n",
    "Micro_F1 = f1_score(y_test,lp_predictions, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, lp_predictions.toarray(), average='micro')\n",
    "Macro_Precision = precision_score(y_test,lp_predictions, average='macro')\n",
    "Macro_Recall = recall_score(y_test,lp_predictions, average='macro')\n",
    "Macro_F1 = f1_score(y_test,lp_predictions, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, lp_predictions.toarray(), average='macro')\n",
    "Samples_Average_Prec = average_precision_score(y_test, lp_predictions.toarray(), average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, lp_predictions.toarray(), average='weighted')\n",
    "Hamming_loss = hamming_loss(y_test,lp_predictions)\n",
    "Ranking_loss = label_ranking_loss(y_test, lp_predictions.toarray())\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _  = roc_curve(y_test, lp_predictions)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.ravel(), lp_predictions.toarray().ravel())\n",
    "Micro_Roc_auc = auc(fpr, tpr)\n",
    "Coverage_error = coverage_error(y_test, lp_predictions.toarray())\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, lp_predictions.toarray())\n",
    "Jaccard_score = jaccard_score(y_test, lp_predictions, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, lp_predictions, average='macro')\n",
    "print(\"LabelPowersetLogisticRegression Accuracy = \",Accuracy)\n",
    "print(\"LabelPowersetLogisticRegression Micro_Precision = \",Micro_Precision)\n",
    "print(\"LabelPowersetLogisticRegression Micro_Recall = \",Micro_Recall)\n",
    "print(\"LabelPowersetLogisticRegression Micro_F1 = \",Micro_F1)\n",
    "print(\"LabelPowersetLogisticRegression Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"LabelPowersetLogisticRegression Macro_Precision = \",Macro_Precision)\n",
    "print(\"LabelPowersetLogisticRegression Macro_Recall = \",Macro_Recall)\n",
    "print(\"LabelPowersetLogisticRegression Macro_F1 = \",Macro_F1)\n",
    "print(\"LabelPowersetLogisticRegression Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"LabelPowersetLogisticRegression Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"LabelPowersetLogisticRegression Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"LabelPowersetLogisticRegression Hamming_loss = \",Hamming_loss)\n",
    "print(\"LabelPowersetLogisticRegression Ranking_loss = \",Ranking_loss)\n",
    "print(\"LabelPowersetLogisticRegression Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"LabelPowersetLogisticRegression Coverage_error = \",Coverage_error)\n",
    "print(\"LabelPowersetLogisticRegression label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"LabelPowersetLogisticRegression Jaccard_score = \",Jaccard_score)\n",
    "print(\"LabelPowersetLogisticRegression Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval4 = ['LabelPowersetLogisticRegression',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. Adapted Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLkNN\n",
    "# Adapted Algorithm\n",
    "# http://scikit.ml/api/api/skmultilearn.adapt.html#skmultilearn.adapt.MLkNN\n",
    "ml_classifier = MLkNN(k=10)\n",
    "# to prevent errors when handling sparse matrices.\n",
    "X_train = lil_matrix(X_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "X_test = lil_matrix(X_test).toarray()\n",
    "ml_classifier.fit(X_train, y_train)\n",
    "# predict\n",
    "ml_predictions = ml_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,ml_predictions.toarray())\n",
    "Micro_Precision = precision_score(y_test,ml_predictions, average='micro')\n",
    "Micro_Recall = recall_score(y_test,ml_predictions, average='micro')\n",
    "Micro_F1 = f1_score(y_test,ml_predictions, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, ml_predictions.toarray(), average='micro')\n",
    "Macro_Precision = precision_score(y_test,ml_predictions, average='macro')\n",
    "Macro_Recall = recall_score(y_test,ml_predictions, average='macro')\n",
    "Macro_F1 = f1_score(y_test,ml_predictions, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, ml_predictions.toarray(), average='macro')\n",
    "Samples_Average_Prec = average_precision_score(y_test, ml_predictions.toarray(), average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, ml_predictions.toarray(), average='weighted')\n",
    "Hamming_loss = hamming_loss(y_test,ml_predictions)\n",
    "Ranking_loss = label_ranking_loss(y_test, ml_predictions.toarray())\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _  = roc_curve(y_test, ml_predictions)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.ravel(), ml_predictions.toarray().ravel())\n",
    "Micro_Roc_auc = auc(fpr, tpr)\n",
    "Coverage_error = coverage_error(y_test, ml_predictions.toarray())\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, ml_predictions.toarray())\n",
    "Jaccard_score = jaccard_score(y_test, ml_predictions, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, ml_predictions, average='macro')\n",
    "print(\"MLkNN Accuracy = \",Accuracy)\n",
    "print(\"MLkNN Micro_Precision = \",Micro_Precision)\n",
    "print(\"MLkNN Micro_Recall = \",Micro_Recall)\n",
    "print(\"MLkNN Micro_F1 = \",Micro_F1)\n",
    "print(\"MLkNN Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"MLkNN Macro_Precision = \",Macro_Precision)\n",
    "print(\"MLkNN Macro_Recall = \",Macro_Recall)\n",
    "print(\"MLkNN Macro_F1 = \",Macro_F1)\n",
    "print(\"MLkNN Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"MLkNN Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"MLkNN Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"MLkNN Hamming_loss = \",Hamming_loss)\n",
    "print(\"MLkNN Ranking_loss = \",Ranking_loss)\n",
    "print(\"MLkNN Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"MLkNN Coverage_error = \",Coverage_error)\n",
    "print(\"MLkNN label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"MLkNN Jaccard_score = \",Jaccard_score)\n",
    "print(\"MLkNN Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval5 = ['MLkNN',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Classifier Chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsc\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d330b1de7d89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#for the next classifier we need to remove from y-train, y-test categories which equal 0 for all train samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcc_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifierChain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcc_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcc_predictions_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcc_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#for plotting metrics as a function of threashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\cc.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, order)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# on X + y[:i] as input space and y[i+1] as output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mX_extended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_input_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_output_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\base\\base.py\u001b[0m in \u001b[0;36m_ensure_input_format\u001b[1;34m(self, X, sparse_format, enforce_sparse)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmatrix_creation_function_for_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_output_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     86\u001b[0m                                  \"\".format(self.format))\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# Read matrix dimensions given, if any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m###################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtocsc\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             coo_tocsr(N, M, self.nnz, col, row, self.data,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "#for the next classifier we need to remove from y-train, y-test categories which equal 0 for all train samples\n",
    "cc_classifier = ClassifierChain(LogisticRegression(solver='warn'))\n",
    "cc_classifier.fit(X_train, y_train)\n",
    "cc_predictions_proba = cc_classifier.predict_proba(X_test)\n",
    "#for plotting metrics as a function of threashold\n",
    "th = []\n",
    "f = []\n",
    "ham = []\n",
    "ac = []\n",
    "for t in range (5,60): # threshold value\n",
    "    y_pred_new = (cc_predictions_proba >= t/100).astype(int)\n",
    "#     print(\"t =\" ,t/100)\n",
    "#     print(\"Accuracy = \",accuracy_score(y_test,y_pred_new))\n",
    "#     print(\"F1 = \",f1_score(y_test,y_pred_new, average=\"micro\"))\n",
    "#     print(\"Hamming loss = \",hamming_loss(y_test,y_pred_new))\n",
    "    th.append(t)\n",
    "    ac.append(accuracy_score(y_test,y_pred_new))\n",
    "    f.append(f1_score(y_test,y_pred_new, average=\"micro\"))\n",
    "    ham.append(hamming_loss(y_test,y_pred_new))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.plot(th, f)\n",
    "    plt.plot(th, ham)\n",
    "    plt.plot(th, ac)\n",
    "    plt.legend(['F1', 'Hamming loss', 'Accuracy'], loc='center left', fontsize = 14)\n",
    "    plt.ylabel(\"metrics\", fontsize = 14)\n",
    "    plt.xlabel(\"threshold\", fontsize = 14)\n",
    "    plt.title(\"Classfier Chain Model\", fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using classifier chains\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(X_train, y_train)\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,predictions.toarray())\n",
    "Micro_Precision = precision_score(y_test,predictions, average='micro')\n",
    "Micro_Recall = recall_score(y_test,predictions, average='micro')\n",
    "Micro_F1 = f1_score(y_test,predictions, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, predictions.toarray(), average='micro')\n",
    "Macro_Precision = precision_score(y_test,predictions, average='macro')\n",
    "Macro_Recall = recall_score(y_test,predictions, average='macro')\n",
    "Macro_F1 = f1_score(y_test,predictions, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, predictions.toarray(), average='macro')\n",
    "Samples_Average_Prec = average_precision_score(y_test, predictions.toarray(), average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, predictions.toarray(), average='weighted')\n",
    "Hamming_loss = hamming_loss(y_test,predictions)\n",
    "Ranking_loss = label_ranking_loss(y_test, predictions.toarray())\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _  = roc_curve(y_test, predictions)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.ravel(), predictions.toarray().ravel())\n",
    "Micro_Roc_auc = auc(fpr, tpr)\n",
    "Coverage_error = coverage_error(y_test, predictions.toarray())\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, predictions.toarray())\n",
    "Jaccard_score = jaccard_score(y_test, predictions, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, predictions, average='macro')\n",
    "print(\"ClassifierChain Accuracy = \",Accuracy)\n",
    "print(\"ClassifierChain Micro_Precision = \",Micro_Precision)\n",
    "print(\"ClassifierChain Micro_Recall = \",Micro_Recall)\n",
    "print(\"ClassifierChain Micro_F1 = \",Micro_F1)\n",
    "print(\"ClassifierChain Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"ClassifierChain Macro_Precision = \",Macro_Precision)\n",
    "print(\"ClassifierChain Macro_Recall = \",Macro_Recall)\n",
    "print(\"ClassifierChain Macro_F1 = \",Macro_F1)\n",
    "print(\"ClassifierChain Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"ClassifierChain Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"ClassifierChain Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"ClassifierChain Hamming_loss = \",Hamming_loss)\n",
    "print(\"ClassifierChain Ranking_loss = \",Ranking_loss)\n",
    "print(\"ClassifierChain Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"ClassifierChain Coverage_error = \",Coverage_error)\n",
    "print(\"ClassifierChain label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"ClassifierChain Jaccard_score = \",Jaccard_score)\n",
    "print(\"ClassifierChain Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval6 = ['ClassifierChain',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. Multiple Binary Classifications - (One Vs Rest Classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'O49939'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\", line 80, in _fit_binary\n    estimator.fit(X, y)\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1532, in fit\n    accept_large_sparse=solver != 'liblinear')\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 719, in check_X_y\n    estimator=estimator)\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 496, in check_array\n    array = np.asarray(array, dtype=dtype, order=order)\n  File \"C:\\Users\\a.berrouachedi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\", line 538, in asarray\n    return array(a, dtype, copy=False, order=order)\nValueError: could not convert string to float: 'O49939'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4cf21e55a8a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLogReg_pipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Training logistic regression model on train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mLogReg_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# calculating test accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mLogprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogReg_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[1;32m--> 216\u001b[1;33m             for i, column in enumerate(columns))\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'O49939'"
     ]
    }
   ],
   "source": [
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),])\n",
    "# Training logistic regression model on train data\n",
    "LogReg_pipeline.fit(X_train,y_train )\n",
    "# calculating test accuracy\n",
    "Logprediction = LogReg_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,Logprediction)\n",
    "Micro_Precision = precision_score(y_test,Logprediction, average='micro')\n",
    "Micro_Recall = recall_score(y_test,Logprediction, average='micro')\n",
    "Micro_F1 = f1_score(y_test,Logprediction, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, Logprediction, average='micro')\n",
    "Macro_Precision = precision_score(y_test,Logprediction, average='macro')\n",
    "Macro_Recall = recall_score(y_test,Logprediction, average='macro')\n",
    "Macro_F1 = f1_score(y_test,Logprediction, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, Logprediction, average='macro')\n",
    "Samples_Average_Prec = average_precision_score(y_test, Logprediction, average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, Logprediction, average='weighted')\n",
    "Hamming_loss = hamming_loss(y_test,Logprediction)\n",
    "Ranking_loss = label_ranking_loss(y_test, Logprediction)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), Logprediction.ravel())\n",
    "Micro_Roc_auc = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "Coverage_error = coverage_error(y_test, Logprediction)\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, Logprediction)\n",
    "Jaccard_score = jaccard_score(y_test, Logprediction, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, Logprediction, average='macro')\n",
    "print(\"OneVsRestClassifier_LogisticRegression Accuracy = \",Accuracy)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Precision = \",Micro_Precision)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Recall = \",Micro_Recall)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_F1 = \",Micro_F1)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_Precision = \",Macro_Precision)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_Recall = \",Macro_Recall)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_F1 = \",Macro_F1)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Hamming_loss = \",Hamming_loss)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Ranking_loss = \",Ranking_loss)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Coverage_error = \",Coverage_error)\n",
    "print(\"OneVsRestClassifier_LogisticRegression label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Jaccard_score = \",Jaccard_score)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval7 = ['OneVsRestClassifier_LogisticRegression',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Evals, columns=['Classifier','Accuracy','Micro_Pre','Micro_Recall','Micro_F1','Micro_Avg_Prec',\n",
    "         'Macro_Prec','Macro_Recall','Macro_F1','Macro_Avg_Prec','Samples_Avg_Prec','Weighted_Avg_Prec','Hamming_loss',\n",
    "         'Ranking_loss','Micro_Roc_auc','Coverage_error','label_ranking_avg_prec_score','Jaccard_score','Jaccard_score_macro'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.33      0.09      0.14        34\n",
      "           2       1.00      0.05      0.09        21\n",
      "           3       0.55      0.29      0.38        38\n",
      "           4       0.50      0.06      0.11        16\n",
      "           5       0.71      0.53      0.61        32\n",
      "           6       0.47      0.14      0.22        64\n",
      "           7       0.00      0.00      0.00        27\n",
      "           8       1.00      0.12      0.21        26\n",
      "           9       0.67      0.47      0.55        47\n",
      "          10       0.96      0.91      0.94       104\n",
      "          11       0.86      0.23      0.36        26\n",
      "          12       0.00      0.00      0.00        21\n",
      "          13       1.00      0.92      0.96        50\n",
      "          14       1.00      0.95      0.97       167\n",
      "          15       0.50      0.11      0.18        27\n",
      "          16       0.85      0.34      0.49        32\n",
      "          17       0.00      0.00      0.00        16\n",
      "          18       0.88      0.34      0.49        41\n",
      "          19       0.50      0.09      0.16        32\n",
      "          20       0.00      0.00      0.00        20\n",
      "          21       0.60      0.23      0.33        40\n",
      "          22       0.57      0.11      0.18        38\n",
      "          23       1.00      0.11      0.20        37\n",
      "          24       0.60      0.15      0.24        20\n",
      "          25       0.00      0.00      0.00        15\n",
      "          26       1.00      0.26      0.41        23\n",
      "          27       0.44      0.12      0.19        33\n",
      "          28       0.00      0.00      0.00        17\n",
      "          29       0.75      0.26      0.39        23\n",
      "          30       0.00      0.00      0.00        29\n",
      "          31       0.80      0.53      0.64        15\n",
      "          32       0.50      0.14      0.21        22\n",
      "          33       0.00      0.00      0.00        25\n",
      "          34       0.33      0.12      0.18        16\n",
      "          35       0.79      0.59      0.68        32\n",
      "          36       0.46      0.28      0.35        68\n",
      "          37       0.00      0.00      0.00        15\n",
      "          38       0.62      0.17      0.26        30\n",
      "          39       0.33      0.05      0.09        19\n",
      "          40       0.75      0.38      0.50        16\n",
      "          41       0.17      0.06      0.09        52\n",
      "          42       0.33      0.07      0.11        46\n",
      "          43       0.67      0.21      0.32        29\n",
      "          44       0.84      0.60      0.70        68\n",
      "          45       0.60      0.12      0.21        24\n",
      "          46       0.00      0.00      0.00        11\n",
      "          47       0.50      0.09      0.15        22\n",
      "          48       0.57      0.11      0.18        37\n",
      "          49       0.81      0.63      0.71        41\n",
      "          50       0.50      0.08      0.14        12\n",
      "          51       1.00      0.03      0.06        30\n",
      "          52       0.82      0.46      0.59       110\n",
      "          53       1.00      0.25      0.40        20\n",
      "          54       0.59      0.28      0.38        36\n",
      "          55       0.83      0.18      0.29        28\n",
      "          56       0.80      0.27      0.40        15\n",
      "          57       1.00      0.19      0.32        21\n",
      "          58       0.50      0.06      0.11        16\n",
      "          59       0.67      0.08      0.15        24\n",
      "          60       0.00      0.00      0.00        17\n",
      "          61       0.72      0.41      0.52        32\n",
      "          62       1.00      0.41      0.58        17\n",
      "          63       0.73      0.56      0.63        80\n",
      "          64       0.44      0.20      0.28        20\n",
      "          65       0.78      0.30      0.44        23\n",
      "          66       0.17      0.02      0.03        52\n",
      "          67       0.00      0.00      0.00        22\n",
      "          68       0.33      0.05      0.09        19\n",
      "          69       0.50      0.06      0.11        17\n",
      "          70       0.40      0.12      0.18        68\n",
      "          71       0.57      0.16      0.25        25\n",
      "          72       0.83      0.20      0.32        25\n",
      "          73       0.17      0.04      0.06        26\n",
      "          74       0.75      0.40      0.52        15\n",
      "          75       0.48      0.27      0.34       115\n",
      "          76       0.75      0.23      0.35        13\n",
      "          77       1.00      0.32      0.49        31\n",
      "          78       0.40      0.13      0.20        15\n",
      "          79       1.00      0.10      0.18        20\n",
      "          80       0.60      0.08      0.15        36\n",
      "          81       0.77      0.51      0.62        47\n",
      "          82       1.00      0.67      0.80        24\n",
      "          83       0.73      0.42      0.54        71\n",
      "          84       0.50      0.16      0.24        50\n",
      "          85       0.56      0.14      0.22        36\n",
      "          86       0.75      0.60      0.67        20\n",
      "          87       0.71      0.19      0.29        27\n",
      "          88       0.26      0.11      0.15        75\n",
      "          89       0.00      0.00      0.00        34\n",
      "          90       0.00      0.00      0.00        35\n",
      "          91       0.00      0.00      0.00        20\n",
      "          92       1.00      0.10      0.17        21\n",
      "          93       0.50      0.11      0.18        63\n",
      "          94       1.00      0.04      0.08        25\n",
      "          95       1.00      0.21      0.35        14\n",
      "          96       0.24      0.15      0.18        48\n",
      "          97       0.39      0.20      0.27        64\n",
      "          98       0.00      0.00      0.00        14\n",
      "          99       0.67      0.09      0.16        22\n",
      "         100       0.43      0.05      0.10        56\n",
      "         101       0.90      0.90      0.90        31\n",
      "         102       0.80      0.15      0.25        27\n",
      "         103       1.00      0.10      0.19        29\n",
      "         104       0.68      0.33      0.44        83\n",
      "         105       0.50      0.09      0.15        22\n",
      "         106       0.60      0.12      0.19        26\n",
      "         107       0.25      0.17      0.20        29\n",
      "         108       0.50      0.05      0.08        22\n",
      "         109       1.00      0.06      0.11        18\n",
      "         110       0.80      0.14      0.24        29\n",
      "         111       0.89      0.39      0.54        41\n",
      "         112       1.00      0.14      0.25        14\n",
      "         113       0.72      0.32      0.44        41\n",
      "         114       0.33      0.04      0.07        26\n",
      "         115       0.83      0.28      0.42        18\n",
      "         116       0.00      0.00      0.00        19\n",
      "         117       0.82      0.46      0.59        70\n",
      "         118       0.50      0.04      0.07        26\n",
      "         119       0.25      0.02      0.04        44\n",
      "         120       0.50      0.03      0.05        37\n",
      "         121       0.67      0.23      0.34        26\n",
      "         122       0.49      0.28      0.35        72\n",
      "         123       0.33      0.06      0.10        17\n",
      "         124       0.47      0.12      0.20        64\n",
      "         125       1.00      0.21      0.35        19\n",
      "         126       0.50      0.03      0.05        35\n",
      "         127       0.00      0.00      0.00        16\n",
      "         128       0.50      0.06      0.10        18\n",
      "         129       0.38      0.21      0.27        66\n",
      "         130       0.33      0.06      0.10        18\n",
      "         131       0.57      0.50      0.53       131\n",
      "         132       0.50      0.05      0.08        22\n",
      "         133       0.00      0.00      0.00        16\n",
      "         134       1.00      1.00      1.00       344\n",
      "         135       0.00      0.00      0.00        32\n",
      "         136       1.00      0.05      0.09        22\n",
      "         137       0.00      0.00      0.00        23\n",
      "         138       0.00      0.00      0.00        44\n",
      "         139       0.60      0.35      0.44        34\n",
      "         140       0.00      0.00      0.00        26\n",
      "         141       0.26      0.09      0.14        64\n",
      "         142       0.00      0.00      0.00        25\n",
      "         143       0.80      0.28      0.41        43\n",
      "         144       0.71      0.40      0.51        43\n",
      "         145       0.62      0.17      0.26        30\n",
      "         146       0.50      0.19      0.27        53\n",
      "         147       1.00      0.07      0.14        27\n",
      "         148       0.50      0.06      0.11        17\n",
      "         149       0.40      0.15      0.21        41\n",
      "         150       0.25      0.06      0.09        18\n",
      "         151       0.70      0.21      0.33        33\n",
      "         152       0.14      0.03      0.04        40\n",
      "         153       0.20      0.06      0.09        36\n",
      "         154       1.00      0.21      0.34        24\n",
      "         155       0.83      0.12      0.21        42\n",
      "         156       0.42      0.18      0.25        85\n",
      "         157       0.25      0.08      0.12        25\n",
      "         158       0.60      0.15      0.24        20\n",
      "\n",
      "   micro avg       0.70      0.29      0.41      5853\n",
      "   macro avg       0.54      0.19      0.26      5853\n",
      "weighted avg       0.59      0.29      0.35      5853\n",
      " samples avg       0.45      0.32      0.35      5853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "#print(multilabel_confusion_matrix(y_test, Logprediction))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test, Logprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.programcreek.com/python/example/81207/sklearn.metrics.roc_curve\n",
    "def print_roc(y_true, y_scores):\n",
    "        '''\n",
    "        Prints the ROC for this model.\n",
    "        '''\n",
    "        fpr, tpr, thresholds = roc_curve(y_test.ravel(), y_scores.ravel())\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)'% auc_score)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show() \n",
    "print_roc(y_test, Logprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=0))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors = cycle(['blue', 'red', 'green'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
