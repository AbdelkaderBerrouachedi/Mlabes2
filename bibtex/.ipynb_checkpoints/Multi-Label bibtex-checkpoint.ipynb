{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/multi-label-text-classification-5c505fdedca8#--responses\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from sklearn.metrics import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "import numpy\n",
    "from skmultilearn.dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of metrics\n",
    "Evals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7395, 1995)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from file 'filename.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, rows, column names with read_csv (see later) \n",
    "data = pd.read_csv(\"bibtex.csv\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train\n",
    "y = data.iloc[:,-159:]\n",
    "X = data.iloc[:,:-159]\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-Label Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Multiple Binary Classifications - (Binary Relevance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1  BinaryRelevance MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model_single_class(input_dim, output_dim):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.ext import Keras\n",
    "KERAS_PARAMS = dict(epochs=10, batch_size=100, verbose=0)\n",
    "clf = BinaryRelevance(classifier=Keras(create_model_single_class, False, KERAS_PARAMS), require_dense=[True,True])\n",
    "clf.fit(X_train, y_train)\n",
    "result = clf.predict(X_test)\n",
    "print(\"BinaryReKeras Accuracy = \",accuracy_score(y_test,result.toarray()))\n",
    "print(\"BinaryReKeras Precision = \",precision_score(y_test,result, average='micro'))\n",
    "print(\"BinaryReKeras Recall = \",recall_score(y_test,result, average='micro'))\n",
    "print(\"BinaryReKeras F1_score = \",f1_score(y_test,result, average='micro'))\n",
    "print(\"BinaryReKeras Hamming loss = \",hamming_loss(y_test,result))\n",
    "\n",
    "Eval1 = ['BinaryRelevance_Keras',accuracy_score(y_test,result.toarray())*100,hamming_loss(y_test,result)*100]\n",
    "Evals.append(Eval1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2  BinaryRelevance SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fe216c1e24a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryRelevance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_dense\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# Predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\br.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0my_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             classifier.fit(self._ensure_input_format(\n\u001b[1;32m--> 162\u001b[1;33m                 X), self._ensure_output_format(y_subset))\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                          accept_large_sparse=False)\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    519\u001b[0m             raise ValueError(\n\u001b[0;32m    520\u001b[0m                 \u001b[1;34m\"The number of classes has to be greater than one; got %d\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                 \" class\" % len(cls))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "# initialize Binary Relevance multi-label classifier\n",
    "# with an SVM classifier\n",
    "# SVM in scikit only supports the X matrix in sparse representation\n",
    "# Import BinaryRelevance from skmultilearn\n",
    "# Import SVC classifier from sklearn\n",
    "# Setup the classifier\n",
    "classifier = BinaryRelevance(classifier=SVC(), require_dense=[False,True])\n",
    "# Train\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"BinaryReSVC Accuracy = \",accuracy_score(y_test,y_pred.toarray()))\n",
    "print(\"BinaryReSVC Precision = \",precision_score(y_test,y_pred, average='micro'))\n",
    "print(\"BinaryReSVC Recall = \",recall_score(y_test,y_pred, average='micro'))\n",
    "print(\"BinaryReSVC F1_score = \",f1_score(y_test,y_pred, average='micro'))\n",
    "print(\"BinaryReSVC Hamming loss = \",hamming_loss(y_test,y_pred))\n",
    "\n",
    "\n",
    "Eval2 = ['BinaryRelevance_SVM',accuracy_score(y_test,y_pred.toarray())*100,hamming_loss(y_test,y_pred)*100]\n",
    "Evals.append(Eval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3  BinaryRelevance GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryReGaussianNB Accuracy =  0.17647058823529413\n",
      "BinaryReGaussianNB Precision =  0.3903002309468822\n",
      "BinaryReGaussianNB Recall =  0.41728395061728396\n",
      "BinaryReGaussianNB F1_score =  0.4033412887828162\n",
      "BinaryReGaussianNB Hamming loss =  0.03439972480220158\n"
     ]
    }
   ],
   "source": [
    "#Binary Relevance GaussianNB\n",
    "BinaryReGaussianNB = BinaryRelevance(GaussianNB())\n",
    "BinaryReGaussianNB.fit(X_train,y_train)\n",
    "br_predictions = BinaryReGaussianNB.predict(X_test)\n",
    "\n",
    "print(\"BinaryReGaussianNB Accuracy = \",accuracy_score(y_test,br_predictions.toarray()))\n",
    "print(\"BinaryReGaussianNB Precision = \",precision_score(y_test,br_predictions, average='micro'))\n",
    "print(\"BinaryReGaussianNB Recall = \",recall_score(y_test,br_predictions, average='micro'))\n",
    "print(\"BinaryReGaussianNB F1_score = \",f1_score(y_test,br_predictions, average='micro'))\n",
    "print(\"BinaryReGaussianNB Hamming loss = \",hamming_loss(y_test,br_predictions))\n",
    "\n",
    "\n",
    "Eval3 = ['BinaryRelevance_GaussianNB',accuracy_score(y_test,br_predictions.toarray())*100,hamming_loss(y_test,br_predictions)*100]\n",
    "Evals.append(Eval3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Label Powerset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelPowerset Accuracy =  0.6811145510835913\n",
      "LabelPowerset Precision =  0.828169014084507\n",
      "LabelPowerset Recall =  0.725925925925926\n",
      "LabelPowerset F1_score =  0.7736842105263158\n",
      "LabelPowerset Hamming loss =  0.011833505331957345\n"
     ]
    }
   ],
   "source": [
    "## initialize label powerset multi-label classifier\n",
    "lp_classifier = LabelPowerset(LogisticRegression())\n",
    "lp_classifier.fit(X_train, y_train)\n",
    "lp_predictions = lp_classifier.predict(X_test)\n",
    "\n",
    "print(\"LabelPowerset Accuracy = \",accuracy_score(y_test,lp_predictions.toarray()))\n",
    "print(\"LabelPowerset Precision = \",precision_score(y_test,lp_predictions, average='micro'))\n",
    "print(\"LabelPowerset Recall = \",recall_score(y_test,lp_predictions, average='micro'))\n",
    "print(\"LabelPowerset F1_score = \",f1_score(y_test,lp_predictions, average='micro'))\n",
    "print(\"LabelPowerset Hamming loss = \",hamming_loss(y_test,lp_predictions))\n",
    "\n",
    "Eval4 = ['LabelPowerset_LogisticRegression',accuracy_score(y_test,lp_predictions)*100,hamming_loss(y_test,lp_predictions)*100,\n",
    "        f1_score(y_test,lp_predictions, average=\"micro\")*100,]\n",
    "Evals.append(Eval4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. Adapted Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLkNN Accuracy =  0.541795665634675\n",
      "MLkNN Precision =  0.822742474916388\n",
      "MLkNN Recall =  0.6074074074074074\n",
      "MLkNN F1_score =  0.6988636363636362\n",
      "MLkNN Hamming loss =  0.014585483316133472\n"
     ]
    }
   ],
   "source": [
    "#MLkNN\n",
    "# Adapted AlgorithmÂ¶\n",
    "# http://scikit.ml/api/api/skmultilearn.adapt.html#skmultilearn.adapt.MLkNN\n",
    "\n",
    "ml_classifier = MLkNN(k=10)\n",
    "# to prevent errors when handling sparse matrices.\n",
    "X_train = lil_matrix(X_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "X_test = lil_matrix(X_test).toarray()\n",
    "ml_classifier.fit(X_train, y_train)\n",
    "# predict\n",
    "ml_predictions = ml_classifier.predict(X_test)\n",
    "# accuracy\n",
    "print(\"MLkNN Accuracy = \",accuracy_score(y_test,ml_predictions.toarray()))\n",
    "print(\"MLkNN Precision = \",precision_score(y_test,ml_predictions, average='micro'))\n",
    "print(\"MLkNN Recall = \",recall_score(y_test,ml_predictions, average='micro'))\n",
    "print(\"MLkNN F1_score = \",f1_score(y_test,ml_predictions, average='micro'))\n",
    "print(\"MLkNN Hamming loss = \",hamming_loss(y_test,ml_predictions))\n",
    "\n",
    "Eval5 = ['Adapted_Algorithm_MLkNN',accuracy_score(y_test,ml_predictions)*100,hamming_loss(y_test,ml_predictions)*100,\n",
    "        f1_score(y_test,ml_predictions, average=\"micro\")*100,]\n",
    "Evals.append(Eval5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Classifier Chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-d330b1de7d89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#for the next classifier we need to remove from y-train, y-test categories which equal 0 for all train samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcc_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifierChain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcc_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcc_predictions_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcc_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#for plotting metrics as a function of threashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\cc.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, order)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n\u001b[1;32m--> 155\u001b[1;33m                 X_extended), self._ensure_output_format(y_subset))\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[0mX_extended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_extended\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1549\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    877\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m    878\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "#for the next classifier we need to remove from y-train, y-test categories which equal 0 for all train samples\n",
    "cc_classifier = ClassifierChain(LogisticRegression(solver='warn'))\n",
    "cc_classifier.fit(X_train, y_train)\n",
    "cc_predictions_proba = cc_classifier.predict_proba(X_test)\n",
    "#for plotting metrics as a function of threashold\n",
    "th = []\n",
    "f = []\n",
    "ham = []\n",
    "ac = []\n",
    "for t in range (5,60): # threshold value\n",
    "    y_pred_new = (cc_predictions_proba >= t/100).astype(int)\n",
    "#     print(\"t =\" ,t/100)\n",
    "#     print(\"Accuracy = \",accuracy_score(y_test,y_pred_new))\n",
    "#     print(\"F1 = \",f1_score(y_test,y_pred_new, average=\"micro\"))\n",
    "#     print(\"Hamming loss = \",hamming_loss(y_test,y_pred_new))\n",
    "    th.append(t)\n",
    "    ac.append(accuracy_score(y_test,y_pred_new))\n",
    "    f.append(f1_score(y_test,y_pred_new, average=\"micro\"))\n",
    "    ham.append(hamming_loss(y_test,y_pred_new))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.plot(th, f)\n",
    "    plt.plot(th, ham)\n",
    "    plt.plot(th, ac)\n",
    "    plt.legend(['F1', 'Hamming loss', 'Accuracy'], loc='center left', fontsize = 14)\n",
    "    plt.ylabel(\"metrics\", fontsize = 14)\n",
    "    plt.xlabel(\"threshold\", fontsize = 14)\n",
    "    plt.title(\"Classfier Chain Model\", fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0da1fd127744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifierChain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Training logistic regression model on train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\cc.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, order)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n\u001b[1;32m--> 155\u001b[1;33m                 X_extended), self._ensure_output_format(y_subset))\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[0mX_extended\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_extended\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1549\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    877\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0;32m    878\u001b[0m                              \u001b[1;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "# using classifier chains\n",
    "# initialize classifier chains multi-label classifier\n",
    "classifier = ClassifierChain(LogisticRegression())\n",
    "# Training logistic regression model on train data\n",
    "classifier.fit(X_train, y_train)\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,predictions.toarray())\n",
    "\n",
    "Micro_Precision = precision_score(y_test,predictions, average='micro')\n",
    "Micro_Recall = recall_score(y_test,predictions, average='micro')\n",
    "Micro_F1 = f1_score(y_test,predictions, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test.toarray(), predictions.toarray(), average='micro')\n",
    "\n",
    "Macro_Precision = precision_score(y_test,predictions, average='macro')\n",
    "Macro_Recall = recall_score(y_test,predictions, average='macro')\n",
    "Macro_F1 = f1_score(y_test,predictions, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test.toarray(), predictions.toarray(), average='macro')\n",
    "\n",
    "Samples_Average_Prec = average_precision_score(y_test.toarray(), predictions.toarray(), average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test.toarray(), predictions.toarray(), average='weighted')\n",
    "\n",
    "Hamming_loss = hamming_loss(y_test,predictions)\n",
    "Ranking_loss = label_ranking_loss(y_test.toarray(), predictions.toarray())\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.toarray(), predictions)\n",
    "Micro_Roc_auc = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    " \n",
    "Coverage_error = coverage_error(y_test.toarray(), predictions)\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test.toarray(), predictions)\n",
    "Jaccard_score = jaccard_score(y_test, predictions, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, predictions, average='macro')\n",
    "\n",
    "\n",
    "print(\"ClassifierChain Accuracy = \",Accuracy)\n",
    "print(\"ClassifierChain Micro_Precision = \",Micro_Precision)\n",
    "print(\"ClassifierChain Micro_Recall = \",Micro_Recall)\n",
    "print(\"ClassifierChain Micro_F1 = \",Micro_F1)\n",
    "print(\"ClassifierChain Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"ClassifierChain Macro_Precision = \",Macro_Precision)\n",
    "print(\"ClassifierChain Macro_Recall = \",Macro_Recall)\n",
    "print(\"ClassifierChain Macro_F1 = \",Macro_F1)\n",
    "print(\"ClassifierChain Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"ClassifierChain Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"ClassifierChain Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"ClassifierChain Hamming_loss = \",Hamming_loss)\n",
    "print(\"ClassifierChain Ranking_loss = \",Ranking_loss)\n",
    "print(\"ClassifierChain Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"ClassifierChain Coverage_error = \",Coverage_error)\n",
    "print(\"ClassifierChain label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"ClassifierChain Jaccard_score = \",Jaccard_score)\n",
    "print(\"ClassifierChain Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval7 = ['ClassifierChain',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. Multiple Binary Classifications - (One Vs Rest Classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier_LogisticRegression Accuracy =  0.6253869969040248\n",
      "OneVsRestClassifier_LogisticRegression Micro_Precision =  0.8836477987421384\n",
      "OneVsRestClassifier_LogisticRegression Micro_Recall =  0.6938271604938272\n",
      "OneVsRestClassifier_LogisticRegression Micro_F1 =  0.7773167358229599\n",
      "OneVsRestClassifier_LogisticRegression Micro_Average_Prec =  0.6216299748288248\n",
      "OneVsRestClassifier_LogisticRegression Macro_Precision =  0.28566924319944176\n",
      "OneVsRestClassifier_LogisticRegression Macro_Recall =  0.25565281364743986\n",
      "OneVsRestClassifier_LogisticRegression Macro_F1 =  0.26640995148033975\n",
      "OneVsRestClassifier_LogisticRegression Macro_Average_Prec =  nan\n",
      "OneVsRestClassifier_LogisticRegression Samples_Average_Prec =  0.7077055383556932\n",
      "OneVsRestClassifier_LogisticRegression Weighted_Average_Prec =  nan\n",
      "OneVsRestClassifier_LogisticRegression Hamming_loss =  0.01107671138630891\n",
      "OneVsRestClassifier_LogisticRegression Ranking_loss =  0.28509099199933674\n",
      "OneVsRestClassifier_LogisticRegression Micro_Roc_auc =  0.8456043091924197\n",
      "OneVsRestClassifier_LogisticRegression Coverage_error =  16.238390092879257\n",
      "OneVsRestClassifier_LogisticRegression label_ranking_average_precision_score =  0.7077055383556925\n",
      "OneVsRestClassifier_LogisticRegression Jaccard_score =  0.6996904024767802\n",
      "OneVsRestClassifier_LogisticRegression Jaccard_score_macro =  0.23932151633215462\n"
     ]
    }
   ],
   "source": [
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),])\n",
    "  \n",
    "# Training logistic regression model on train data\n",
    "LogReg_pipeline.fit(X_train,y_train )\n",
    "    \n",
    "# calculating test accuracy\n",
    "Logprediction = LogReg_pipeline.predict(X_test)\n",
    "\n",
    "# accuracy   None, 'micro', 'macro', 'weighted', 'samples'\n",
    "Accuracy = accuracy_score(y_test,Logprediction)\n",
    "\n",
    "Micro_Precision = precision_score(y_test,Logprediction, average='micro')\n",
    "Micro_Recall = recall_score(y_test,Logprediction, average='micro')\n",
    "Micro_F1 = f1_score(y_test,Logprediction, average='micro')\n",
    "Micro_Average_Prec = average_precision_score(y_test, Logprediction, average='micro')\n",
    "\n",
    "Macro_Precision = precision_score(y_test,Logprediction, average='macro')\n",
    "Macro_Recall = recall_score(y_test,Logprediction, average='macro')\n",
    "Macro_F1 = f1_score(y_test,Logprediction, average='macro')\n",
    "Macro_Average_Prec = average_precision_score(y_test, Logprediction, average='macro')\n",
    "\n",
    "Samples_Average_Prec = average_precision_score(y_test, Logprediction, average='samples')\n",
    "Weighted_Average_Prec = average_precision_score(y_test, Logprediction, average='weighted')\n",
    "\n",
    "Hamming_loss = hamming_loss(y_test,Logprediction)\n",
    "Ranking_loss = label_ranking_loss(y_test, Logprediction)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), Logprediction.ravel())\n",
    "Micro_Roc_auc = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    " \n",
    "Coverage_error = coverage_error(y_test, Logprediction)\n",
    "label_ranking_avg_prec_score = label_ranking_average_precision_score(y_test, Logprediction)\n",
    "Jaccard_score = jaccard_score(y_test, Logprediction, average='samples')\n",
    "Jaccard_score_macro = jaccard_score(y_test, Logprediction, average='macro')\n",
    "\n",
    "\n",
    "print(\"OneVsRestClassifier_LogisticRegression Accuracy = \",Accuracy)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Precision = \",Micro_Precision)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Recall = \",Micro_Recall)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_F1 = \",Micro_F1)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Average_Prec = \",Micro_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_Precision = \",Macro_Precision)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_Recall = \",Macro_Recall)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_F1 = \",Macro_F1)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Macro_Average_Prec = \",Macro_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Samples_Average_Prec = \",Samples_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Weighted_Average_Prec = \",Weighted_Average_Prec)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Hamming_loss = \",Hamming_loss)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Ranking_loss = \",Ranking_loss)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Micro_Roc_auc = \",Micro_Roc_auc)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Coverage_error = \",Coverage_error)\n",
    "print(\"OneVsRestClassifier_LogisticRegression label_ranking_average_precision_score = \",label_ranking_avg_prec_score)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Jaccard_score = \",Jaccard_score)\n",
    "print(\"OneVsRestClassifier_LogisticRegression Jaccard_score_macro = \",Jaccard_score_macro)\n",
    "Eval7 = ['OneVsRestClassifier_LogisticRegression',Accuracy,Micro_Precision,Micro_Recall,Micro_F1,Micro_Average_Prec,\n",
    "         Macro_Precision,Macro_Recall,Macro_F1,Macro_Average_Prec,Samples_Average_Prec,Weighted_Average_Prec,Hamming_loss,\n",
    "         Ranking_loss,Micro_Roc_auc,Coverage_error,label_ranking_avg_prec_score,Jaccard_score,Jaccard_score_macro]\n",
    "Evals.append(Eval7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90        33\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.91      0.90      0.91        94\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.78      0.84      0.81        38\n",
      "          10       0.00      0.00      0.00         7\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         3\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       1.00      1.00      1.00         5\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       1.00      0.82      0.90        11\n",
      "          24       1.00      1.00      1.00        18\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.86      0.52      0.65        23\n",
      "          32       0.80      0.84      0.82        43\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         6\n",
      "          35       0.00      0.00      0.00         7\n",
      "          36       0.85      0.92      0.88        12\n",
      "          37       0.00      0.00      0.00         8\n",
      "          38       1.00      0.54      0.70        13\n",
      "          39       0.00      0.00      0.00         7\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.90      0.75      0.82        24\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       1.00      1.00      1.00         9\n",
      "          44       0.88      0.47      0.61        15\n",
      "\n",
      "   micro avg       0.88      0.69      0.78       405\n",
      "   macro avg       0.29      0.26      0.27       405\n",
      "weighted avg       0.74      0.69      0.71       405\n",
      " samples avg       0.76      0.72      0.72       405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "#print(multilabel_confusion_matrix(y_test, Logprediction))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_test, Logprediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_roc(y_true, y_scores):\n",
    "        '''\n",
    "        Prints the ROC for this model.\n",
    "        '''\n",
    "        fpr, tpr, thresholds = roc_curve(y_test.ravel(), Logprediction.ravel())\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_roc(y_test, Logprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Evals, columns=['Classifier','Accuracy','Precision','Recall','F1_score','Hamming_loss'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9ff40232e7a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n\u001b[0m\u001b[0;32m     31\u001b[0m              \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ROC curve of class {0} (area = {1:0.2f})'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m              ''.format(i, roc_auc[i]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lw' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=0))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors = cycle(['blue', 'red', 'green'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
